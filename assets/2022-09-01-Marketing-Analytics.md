---
layout: post
title: How to measure and optimize Marketing's contribution to enterprise value
subtitle: ROMI vs MMM vs MTA
cover-img: /assets/img/ROMI.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/ROMI.jpg
tags: [ROMI, MMM, MTA]
---

Marketing's  biggest C-suite communication challenge is to accurately prove how effective marketing strategies are on financial outcomes. This struggle ranges from fact-based past performance assessments just as much as empirically deciding whether to decrease or increase Marketing Budgets, or even, at a more tactical level, which future marketing investments will return the greater pay off.

Beyond cost control and profitability decision making, adopting a financial measure like 'Return On Marketing Investment' (ROMI) outlook sharpens the focus on business goals. By comparing the returns and costs of marketing, ROMI encourages transparency and builds trust as financial impact is a language that top management understands and evaluates against. ROMI helps compare marketing decisions by revealing the ones with the higher efficiency.

The ROMI can help in answering many marketing questions. For example:
1) How much return do we get from spending X amount on marketing?
2) How should we allocate our marketing budget to maximise our sales?

ROMI = Incremental margin − Marketing investment / Marketing investment 

**give WF example**

The measure enables the comparison of efficiencies between different marketing investments. It is typically calculated by doing a baseline-lift valuation on short-term sales, where the effect of a marketing effort on sales is separated from the level of sales that would have been reached without the marketing effort. 

Randomised experiments have also been applied successfully to
measure marketing effectiveness, and their cost has been brought down
by the Internet and digital measurement infrastructures 

**Plan Strategically with Marketing Mix Modeling**

The most commonly studied and applied ROMI method is marketing mix modelling (MMM) or when media is involved, 
media mix modelling, where historical data is used to represent sales as a function of advertising and marketing variables,
such as media spend, number of views and product price, and control
variables, such as weather, seasonality, and market competition. This can be used to adjust
marketing budgets. A lack of granular data, however, commonly limits the scope of MMM just
to studying the marketing effectiveness on a national level rather than,
for example, regionally or by product category. This limitation reduces
opportunities in detailed decision making and budgeting. MMM also
suffers from various downsides, such as lack of data, untested assumptions of market behaviour and various biases. 

MMM often suffers from various downsides, such as lack of data, deficient model forms and biases. Improving modelling granularity would enable marketers to analyse performance on lower levels and broaden their discussion on improvements. 

Marketing mix modeling is a top down modelling solution that measures the high-level impact of a range of marketing efforts on sales, will help guide budget allocation by showing how channel (incremental) performance compares, to get the optimal marketing mix. 
It models sales over time across digital and offline channels, as a function of advertising sales, other marketing variables and even control variables like weather, economic conditions, seasonality and competition.

Because of the impracticality of the conventional methods for studying
causality, companies often resort to using more straightforward marketing
mix modelling (MMM), aka media mix modelling, techniques. MMM attempts to model the demand response by fitting a model, typically an OLS
regression with various drivers and control factors, in historical data (Chan
and Perry, 2017). The results commonly include ROAS estimates for advertising channels and a break-down of the effect of different drivers. The
technique is cheap, fast and straightforward to apply as it typically involves
no experimentation. Yet, the validity of the results is often questionable.
The models are often based on inaccurate or unverified assumptions about
the nature of marketing environment (Zhang and Vaver, 2017) and are
merely capable of producing correlational, not causal results (Chan and
Perry, 2017).

**Optimize Tactically with Multi-Touch Attribution**
multitouch attribution (MTA) is a solution that suggest ways to optimize their marketing performance. 

Multi-touch attribution, on the other hand, offers tactical insights for short-term optimization. It focuses on addressable channels and leverages granular, user-level data to analyze performance in near real time. It does this by calculating and assigning fractional KPI credit to the marketing touchpoints and dimensions (publisher, placement, creative, offer, etc.) along the consumer journey that influenced a sales or other desired outcome. Marketers can use this insight to make smarter tactical decisions, such as which call to action to use or which keywords to bid on.

Attribution is the process of determining the relative contribution of individual campaign impressions
towards a goal for the purpose of performance measurement and optimization. The dominant
attribution methodology is last-touch, which assigns credit to only the last ad that a consumer
interacted with, before taking the desired action of the campaign. However, the last-touch model is
flawed because individuals are usually exposed to multiple advertising channels before making any 
purchasing decision. Therefore, a fundamental problem in measuring advertising effectiveness is to
quantify how revenue should be attributed to multiple touch-points along consumers' conversion
paths, which is the sequence, timing, and engagement in advertising channels along the purchase
funnel.
MTA is a solution for this measurement challenge since it assigns credit to multiple touch points
along the path to conversion. By assembling information about user characteristics, media touch
points, and sales/conversion data, marketers can understand which combination of channels,
audience targets, publishers, devices, creatives, search keywords, or other marketing considerations
are performing most effectively against their Key Performance Indicator (KPI). Thus, they are widely
regarded by practitioners as a proxy for optimizing campaign performance. Contrary to media mix modeling, it is a bottom-up measurement approach that
requires individual-level data.

**Achieve Better Results by Combining Methods**

By combining both approaches, marketers can further corroborate which channels are contributing
to the pre-defined KPIs while preventing misguided conclusions when gaps between these two
methods arise. For instance, a marketer may use MTA to determine the relative contributions of
display and paid search tactics to online revenue. Meanwhile, they may also use marketing mix
modeling to estimate the impact of those same tactics on offline sales. Blending the detailed view
from MTA with the higher-level analysis provided by marketing mix modeling, companies gain more
accurate measurements. However, the different data sources and levels of data capture make the
automated reconciliation of the two approaches difficult. 

Marketers’ need for an integrated view of their marketing performance is as critical as ever. While marketing mix modeling and multi-touch attribution have their distinct advantages, marketers can realize the highest returns when they are used in tandem. By bringing insights from both methods of analysis together, marketers can get the comprehensive view of performance they need to inform their next best action within and across channels.

For example, consider a brand that is running multiple campaigns across a number of online and offline channels. Using marketing mix modeling, the brand can analyze all the drivers of performance and determine how to best allocate its budget between channels on a quarterly or annual basis. Using multi-touch attribution, the brand can then drill down deeper and allocate channel budgets to the highest-performing publishers, placements, keywords, creatives, and other tactics while campaigns are still in flight. Armed with this strategic -and tactical-level insight, brands can make a broad array of decisions to maximize the efficiency and effectiveness of their entire marketing portfolios.

Most brands today rely on both online and offline channels to drives sales, revenue and other desired business outcomes. By leveraging a holistic measurement approach that reconciles data and insight from marketing mix modeling and multi-touch attribution, marketers can enjoy the truly comprehensive view they need to make the right decisions, at the right time, to optimize performance across every area of investment.







Data used to fit marketing mix models are typically historical weekly or monthly aggregated national
data, although geo-level data can be used. The data includes:
 response data, typically sales but can be other KPI
 media metrics by channel, such as impressions, clicks, GRPs, with the cost being the most
commonly used
 marketing metrics such as price, promotion, product distribution
 control factors such as seasonality, weather or competition.
The response data needs to be at the same level of granularity as the ads spend data. So, while an
advertiser may have precise SKU level data, advertising is usually done at a brand or
product level over an entire country. For the response data, such as sales, advertisers have in place a
robust data collection mechanism. However, media data is more challenging to collect, as ad
campaigns are often executed through several intermediaries, such as agencies or online platforms.
Since it is difficult to get competitor variables for pricing, promotion, and distribution through thirdparties, these variables are often omitted (Chan & Perry, 2017).


MMM typically uses four types of
data to fit their models:
• response data, which are typically volume or sales data,
• media metrics, which are commonly media spending data but sometimes other KPIs such as impressions and clicks,
• marketing metrics such as price, promotions, product distribution,
and
• control factors such as seasonality, weather and market competition.

If suitable data are available, modellers can fit models on various levels
of data aggregation, for example, ranging from the level of an individual
product to the total business unit level, as presented in Figure 2.5 by Cain
(2010).

The lower the level of the fitting, the more detailed conclusions
can be drawn from the results. However, data granularity often limits
the choice. As described by Chan and Perry (2017), companies typically
have granular sales data on SKU or store level but do their advertising
on a higher level over an entire country. As the data types in the model
should preferably be on the same aggregation level, the least granular
data type often sets the granularity of the whole model. Thus, models
are often fitted on the national level using weekly or monthly aggregated
data. Moreover, some of the data types may be difficult to obtain. For
example, companies often omit competitor data, such as marketing efforts
and prices, or ad exposure data, especially for offline media, because of
the difficulty of collecting reliable data. The omission can, in turn, lead to
inaccuracies in modelling. Overall, the lack of (reliable) data is one of the
main limitations of MMM.

 Limitations of marketing mix modelling
As described by Chan and Perry (2017), the results from a regression-based
marketing mix model cannot be claimed to be causal in general, but they
are likely to be more trustworthy when:
• enough data are available to estimate all the parameters in the model,
• useful variability exists in the advertising levels and control variables,
• the model inputs vary independently,
• the model accounts for all the important sales drivers, and
• the model captures the causal relationship between variables.

Despite the importance of these conditions, models often fail to meet them,
limiting not only the reliability of results and but also the scope of the
analysis. Overall, these and many other challenges limit the opportunities
in MMM:
The lack of data limits the reliability of the results and the model granularity. As mentioned in Section 2.3.1, companies typically may have
accurate data on sales but lack granular data on marketing. Low
granularity in one data type can limit the whole model to the same
level, forcing the modeller to aggregate other data types. The aggregation leads to a data set with a low number of data points. For
example, a three-year data set of weekly-aggregated data has only
156 data points. If a company has several advertising channels, each
of which is modelled with several parameters, the number of data
points per parameter in the model can quickly become quite low. The
result might be an unstable regression fit that gives poor estimates
(Chan and Perry, 2017). Many researchers have suggested that the
number of observations should be at least five times the number of
parameters (Leeflang et al., 2015). The lack of data can also lead to
the omission of variables. For example, companies often fail to gather
data about various control activities with a sales impact, such as competitor activity, leading to possible errors because of their omission.

Data reliability is also crucial for the reliability of results. If the modeller feeds inaccurate data to the model, it will only produce inaccurate results. One typical source of inaccuracies is the lack of
systematic data collection. For example, Karmann et al. (2015) note
that it is often a significant challenge for companies to measure their
marketing spending fully. Spending may, for example, become buried
in the budgets of different departments and local subsidiaries and
never become registered in the main marketing department.

A limited range of data creates extrapolation uncertainty when esti19
Measuring marketing effectiveness
mating sales outside the observed budget range (Chan and Perry,
2017). For example, if an advertiser wants to estimate the average
ROAS of an advertising channel, it needs to estimate the level of
sales at zero spending. If no data near zero spending is available,
extrapolation may produce inaccurate results if the S-curve suddenly
changes outside the available range. Thus, a model may produce accurate results for the marginal ROAS but fail to produce reasonable
estimates for the total ROAS.

The lack of model validation and evaluation limits model reliability.
As described by Zhang and Vaver (2017), drawing causal results
from MMM requires making assumptions about the nature of the
marketing environment. Although these assumptions are inevitably
inaccurate to some extent, they also remain unidentified or unverified
in many situations. In some cases, they may also even be unverifiable. The inaccuracies and omissions of assumptions, in turn, reduce
the reliability of the results. Consequently, Zhang and Vaver state
that both observational and experimental methods require careful
evaluation and validation. With observational methods, such as
marketing mix modelling, modellers should attempt to verify the
accuracy of result estimates against a source of truth, for example,
from a simulation experiment.

Correlated input parameters are a typical problem with MMM: advertisers often seek to maximise the impact of marketing efforts by
investing in them in a correlated way. For example, an advertising
channel could be observed at a high level only when a significant
discount is in place or only during a specific season. In a linear
regression model, this correlation can lead to coefficient estimates
with variance and thus, lead to a wrong attribution of sales to the
advertising channel (Chan and Perry, 2017).

Selection bias is a major hurdle for MMM. As described by Chan and
Perry (2017), it occurs when an input media variable correlates with
an unobservable demand parameter that drives sales. When that
parameter is left outside the regression, the model falsely attributes
sales to the media instead of the unobservable parameter. The bias
can be caused, for example, by:
1. Ad targeting – Especially in digital channels, selection bias occurs when ads are shown to people who are already interested in the
product, for example, when showing ads for a related search query.
If the underlying interest remains unaccounted for, it can lead to
false attribution.

2. Seasonality – Unknown or inaccurately modelled seasonality can
lead to selection bias as well. For example, a holiday can cause an
increase in sales that becomes falsely attributed to an advertising
channel. Similarly, competitors’ marketing efforts are not often
accounted for because no data of them are often available.

3. Funnel effects – Selection bias also occurs when the level of one
advertising channel affects the level of another one. For example, a
TV ad might drive more search queries leading to more paid search
ads.

Short-termism is a weakness of MMM as well. Conventional MMM
focuses on measuring short-term incremental sales that will consequently, only provide an estimate of the short-term ROAS. Cain
(2010) repeats the critique by Ambler and Roberts (2005) and Rust
et al. (2004) by stating that this focus disregards the potential brandbuilding and brand-eroding effects of marketing and often leads to a
bias towards promotion activity, where incremental sales are more
immediate than in, for example, media activity. He suggests that to
measure long-term effects, models must also focus on the base sales
component of the model. The base sales reflect the changes in underlying marketing assets, for example, by growing when new customers
convert into loyal customers that make repeated purchases. 

However, according to Cain, the standard OLS regression models are only
capable of imposing a fixed or deterministic baseline that prevents
the analysis of the long-term impact of marketing. Consequently, he
suggests the use of time series regression models to decompose the
sales into short-term (incremental) and long-term base (trend) sales.

Past performance may not be the best indicator for future performance.
Conventional MMM only provides an estimate of the past performance but does not specifically attempt to estimate what the performance will be in the future. Customer behaviour and market
conditions may change in the future and affect marketing performance and S-curves. Thus, the results from MMM should be used
with caution when making decisions.

ROMI-managed companies extensively use econometric or marketing mix models to aid the marketing mix decision-making process. The models help optimize ROMI beyond improving the measurement of returns; they allow marketing analysts to virtually estimate potential outcomes across a variety of circumstances performing “what-if scenarios” and to evaluate more quickly and efficiently a wide range of alternative options. MMM adds a critically important capability to ROMI management when building on a foundation of definitions and metrics developed through cross-functional teamwork.

Marketers have used MMM to move beyond cost management to optimize their mix and manage their top-line opportunities.

Minute Maid has turned its MMMs into a potent tool for increasing the payback on its advertising spending. These models are updated every six months for all major brands and the learning gained in the process is used for planning purposes.

MMMs allow marketers to estimate potential outcomes across a variety of circumstances—able to evaluate alternative hypotheses and select those most likely to payoff and to test them more rigorously because they do not have to test a thousand options. MMM tools can be productive as a means by which users enrich their judgmental processes by adding to their learning.

MMM is often criticized for its “rear-view mirror” or after the fact perspective of marketing mix impact. However, new simulation models can provide scenarios for managers to assess future potential results. 

To aid in evaluating new products, they have begun Monte Carlo simulations integrating the degrees of uncertainty and drivers of a project. The simulations enable the marketing team to assess the range of potential outcomes and to apply market models and to assess discounted cash flow. The analysis allows the understanding of likely outcomes to gain a degree of confidence of the amount of risk. Their risk-adjustment net-present-value model adjusts the hurdle rate over the life of the project to more accurately reflect the degree of risk that the organization is taking.“What-if” simulations permit marketing analysts to evaluate their databases and models, as well as testing out alter-native marketing options. Also, “What-if” or “Due-to” analyses can turn a postmortem on a disappointing promotion into a springboard to new, more effective programs for the future.
