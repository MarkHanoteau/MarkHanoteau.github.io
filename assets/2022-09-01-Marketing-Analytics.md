---
layout: post
title: How to measure and optimize Marketing's contribution to enterprise value
subtitle: ROMI vs MMM vs MTA
cover-img: /assets/img/ROMI.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/ROMI.jpg
tags: [ROMI, MMM, MTA]
---

Marketing's  biggest C-suite communication challenge is to accurately prove how effective marketing strategies are on financial outcomes. This struggle ranges from fact-based past performance assessments just as much as empirically deciding whether to decrease or increase Marketing Budgets, or even, at a more tactical level, which future marketing investments will return the greater pay off.

Beyond cost control and profitability decision making, adopting a financial measure like 'Return On Marketing Investment' (ROMI) outlook sharpens the focus on business goals. By combining the returns and costs of marketing, ROMI encourages transparency and builds credibility as financial impact is a language that top management understands and evaluates against. 

ROMI = Incremental margin − Marketing investment / Marketing investment 

The measure enables the comparison of efficiencies between different marketing investments. It is typically calculated by doing a baseline-lift valuation on short-term sales, where the effect of a marketing effort on sales is separated from the level of sales that would have been reached without the marketing effort. 

**Plan Strategically with Marketing Mix Modeling**

The most commonly studied and applied method is marketing mix modelling (MMM), aka
media mix modelling, where a regression model is fitted to historical data
to represent sales as a function of advertising and marketing variables,
such as media spend, number of views and product price, and control
variables, such as weather, seasonality, and market competition. The
outputs are typically ROAS figures for media, which can be used to adjust
marketing budgets. The method is popular as it requires no experiments
and is somewhat simple to implement. According to Chan and Perry (2017),
a lack of granular data, however, commonly limits the scope of MMM just
to studying the marketing effectiveness on a national level rather than,
for example, regionally or by product category. This limitation reduces
opportunities in detailed decision making and budgeting. MMM also
suffers from various downsides, such as lack of data, untested assumptions of market behaviour and various biases. To counter many of these problems,
Chan and Perry suggest three areas of improvement for MMM:
1. Better data
2. Better models
3. Model validation through simulation

Marketing mix modeling is a top down modelling solution that measures the high-level impact of a range of marketing efforts on sales, will help guide budget allocation by showing how channel (incremental) performance compares, to get the optimal marketing mix. 
It models sales over time across digital and offline channels, as a function of advertising sales, other marketing variables and even control variables like weather, economic conditions, seasonality and competition.

**Optimize Tactically with Multi-Touch Attribution**
multitouch attribution (MTA) is a solution that suggest ways to optimize their marketing performance. 

Multi-touch attribution, on the other hand, offers tactical insights for short-term optimization. It focuses on addressable channels and leverages granular, user-level data to analyze performance in near real time. It does this by calculating and assigning fractional KPI credit to the marketing touchpoints and dimensions (publisher, placement, creative, offer, etc.) along the consumer journey that influenced a sales or other desired outcome. Marketers can use this insight to make smarter tactical decisions, such as which call to action to use or which keywords to bid on.

Attribution is the process of determining the relative contribution of individual campaign impressions
towards a goal for the purpose of performance measurement and optimization. The dominant
attribution methodology is last-touch, which assigns credit to only the last ad that a consumer
interacted with, before taking the desired action of the campaign (Interactive Advertising Bureau,
2017). In this case, the desired action of the campaign was for users to participate online by
registering a set of products they had bought in physical stores. However, the last-touch model is
flawed because individuals are usually exposed to multiple advertising channels before making any 
purchasing decision. Therefore, a fundamental problem in measuring advertising effectiveness is to
quantify how revenue should be attributed to multiple touch-points along consumers' conversion
paths, which is the sequence, timing, and engagement in advertising channels along the purchase
funnel (Zhao, Mahboobi, & Bagheri, 2019).
MTA is a solution for this measurement challenge since it assigns credit to multiple touch points
along the path to conversion. By assembling information about user characteristics, media touch
points, and sales/conversion data, marketers can understand which combination of channels,
audience targets, publishers, devices, creatives, search keywords, or other marketing considerations
are performing most effectively against their Key Performance Indicator (KPI). Thus, they are widely
regarded by practitioners as a proxy for optimizing campaign performance (Interactive Advertising
Bureau, 2017). Contrary to media mix modeling, it is a bottom-up measurement approach that
requires individual-level data (Gartner, 2018).

**Achieve Better Results by Combining Methods**

By combining both approaches, marketers can further corroborate which channels are contributing
to the pre-defined KPIs while preventing misguided conclusions when gaps between these two
methods arise. For instance, a marketer may use MTA to determine the relative contributions of
display and paid search tactics to online revenue. Meanwhile, they may also use marketing mix
modeling to estimate the impact of those same tactics on offline sales. Blending the detailed view
from MTA with the higher-level analysis provided by marketing mix modeling, companies gain more
accurate measurements. However, the different data sources and levels of data capture make the
automated reconciliation of the two approaches difficult. As a result, some providers offer custom
unified measurement solutions (Gartner, 2018).

Marketers’ need for an integrated view of their marketing performance is as critical as ever. While marketing mix modeling and multi-touch attribution have their distinct advantages, marketers can realize the highest returns when they are used in tandem. By bringing insights from both methods of analysis together, marketers can get the comprehensive view of performance they need to inform their next best action within and across channels.

For example, consider a brand that is running multiple campaigns across a number of online and offline channels. Using marketing mix modeling, the brand can analyze all the drivers of performance and determine how to best allocate its budget between channels on a quarterly or annual basis. Using multi-touch attribution, the brand can then drill down deeper and allocate channel budgets to the highest-performing publishers, placements, keywords, creatives, and other tactics while campaigns are still in flight. Armed with this strategic -and tactical-level insight, brands can make a broad array of decisions to maximize the efficiency and effectiveness of their entire marketing portfolios.

Most brands today rely on both online and offline channels to drives sales, revenue and other desired business outcomes. By leveraging a holistic measurement approach that reconciles data and insight from marketing mix modeling and multi-touch attribution, marketers can enjoy the truly comprehensive view they need to make the right decisions, at the right time, to optimize performance across every area of investment.










A model that could measure
the underlying performance structure, starting from promotions and other
low-level activities, would facilitate more granular decision making and
possibly have a more significant impact on marketing performance.

Overall, a gap seems to exist
in research for a complete retail marketing mix model that would support
the retailers in decision making on all levels with accurate marketing
performance data.

MMM often suffers from
various downsides, such as lack of data, deficient model forms and biases. Researchers
have consequently suggested improving it through better data, better models and model
validation. However, researchers mainly discuss these areas as a way to improve model
accuracy rather than to widen the scope of analysis. Improving modelling granularity
would enable marketers to analyse performance on lower levels and broaden their discussion on improvements. Higher granularity could particularly support the retail industry,
where marketing is a complex operation because of wide product ranges, geographical
reaches and customer bases

The ROMI compares the returns and costs
of marketing, thus recognising marketing as an investment. A marketing
decision with a positive ROMI can be deemed a justified investment and
one with a negative ROMI unjustified. The measure also helps in comparing marketing decisions by revealing the ones with higher efficiency.
The simple formula, however, leaves a lot open for interpretation. For
example, how should marketers measure the incremental margins? What
spending should be included in the measurement? Overall, Farris et al.
(2015) identify three primary sources of variation in ROMI measurement:

The **incremental returns** may be measured in different ways. A typical
practice is to do a baseline–lift valuation that splits sales into a baseline, which would have been reached without the specific marketing
effort(s), and into an incremental uplift part, which can be attributed
to the marketing effort(s) (Farris et al., 2015). The incremental uplift
part is then used in the calculation of the ROMI. Different modellers
may, however, define the baseline and incremental sales differently. A
common approach (e.g. by Cain (2010)) is to define the baseline as the
long-term or trend component of the sales time series that is driven
by the underlying consumer preferences (i.e. the marketing assets),
regular shelf price, distribution and other underlying factors, and
the incremental sales as the week-to-week sales fluctuation driven
by marketing and promotions.
To derive more accurate results, some models further dissect the
incremental sales. For example, Silva-Risso et al. (1999) divide incremental sales of promotions into ‘borrowed’ and ‘truly incremental’
(see Figure 2.3). The borrowed sales are purchases that consumers
would have done in the future but were accelerated or cannibalised
by stockpiling because of the promotion. Other such side effects, such
as cannibalisation and halo, may also be taken into account.
Besides incremental sales, ROMI measurement can also be based
on cost-savings, conversion rates and changes in customer equity
and marketing assets (Farris et al., 2015). The changes in customer
equity and marketing assets can be used to estimate the long-term
ROMI, although measuring the effects and setting a reliable baseline
may turn out to be difficult (Stewart, 2009).

The **scope of the ROMI measure** can also change. For example, it can
range from measuring the overall marketing impact to the impact of
an individual campaign, promotion, ad or ad view. The measure can
appear under new names when changing the scope, for example, as
return on advertising spending (ROAS) when discussing advertising
spending. Overall, the ROMI can be adapted to support both strategic
and tactical decisions at various levels of the organisation.

The **range of the ROMI** can take three different forms: total, incremental
and marginal. The total ROMI evaluates the return on all spending,
the incremental ROMI the return on a specified spending increment
and the marginal ROMI describes the return gained when increasing
spending with one unit (Farris et al., 2015). These forms can be useful
in different decisions. For example, the total ROMI can be used to
evaluate whether an investment is profitable in general, whereas
the incremental and marginal ROMI figures can be used to evaluate
whether it is worth putting more money into an investment.

Because of all the possible variations, marketers and managers can easily
misinterpret ROMI numbers. Consequently, Farris et al. (2015) recommend
that marketers fully disclose their definition and measurement method
of the ROMI to promote transparency and to support effective decision
making.

Besides just calculating the current ROMI, marketers also often attempt
to estimate the ROMI at other levels of spending. Typically, the estimate
takes the form of an S-curve that is shaped by two inherent characteristics
of media spending: the necessity to have a certain level of awareness
before marketing starts to be effective and the diminishing returns of
media investment (Mantia, 2015; Wang et al., 2017). An example of such
curves is given in Figure 2.4 by Karmann et al. (2015). For each point on
the curves, the total and marginal ROAS are calculable. The definition of
ROAS is slightly different from the ROMI as the advertising spending is
not subtracted from the incremental profit.

When using ROMI figures to make decisions, it is essential to distinguish
effectiveness and efficiency. Effectiveness refers to the ability to reach a
goal, whereas efficiency refers to the ability to do so with the least amount
of resources.
For companies, the goal is to make a profit. Thus, the ROMI measures the
efficiency of marketing efforts rather than their effectiveness. The upper
part of the ROMI equation, in turn, represents effectiveness. Although
improving efficiency, in general, also leads to improving effectiveness,
it may fail in some cases. Imagine two mutually exclusive marketing
projects: the first one returning EUR 100 million for a EUR 50 million
investment and the second one returning EUR 10 million for a EUR 2
million investment. The first one has a higher net return (e50 mill. vs
e8 mill.) but a lower ROMI (100% vs 400%). Thus, the goal in marketing
should be to maximise effectiveness rather than just efficiency, even if it
reduces efficiency (Farris et al., 2015; Hanssens and Pauwels, 2016). One
way to reach this goal is to use incremental ROMI between two choices
(Farris et al., 2015). In our example, we get a 187.5% incremental ROMI
((100 − 10)/(50 − 2) · 100% = 187.5%) when selecting the first project over
the second one.

To reach higher profits, marketers should not blindly shift budgets toward
high ROMI marketing efforts. Low ROMI operations may be saturated
but effective. High ROMI operations may, in some cases, become quickly
saturated, and sudden shifts towards them can lead to lower effectiveness.
Moreover, the ROMI does not, by default, tell about the risks involved investments. Additional investment into an activity that has performed well
in the past can always fail. Thus, marketers should consider marketing
spending as an investment and carefully approach the decisions with the
help relevant information, e.g. ROMI figures, S-curve estimates, forecasts
and risk analyses.
Although the ROMI is a useful measure in marketing decision making,
some researchers criticise it. For example, Ambler and Roberts (2005) and
Rust et al. (2004) note that the ROMI often dismisses the potential impact
of marketing investments on long-term marketing assets, thus yielding
inaccurate results on the profitability of investments. Consequently, they
recommend using other long-term measures alongside the ROMI. Despite
the critique, the ROMI remains a simple and effective way to assess the
short-term impact of investments. Moreover, if a company manages to
quantify the financial impact of long-term effects, it can include them into
the ROMI to form a complete estimate.

Overall, the ROMI can help marketers to gain back the trust of CEOs.

The ROMI can help in answering many marketing questions. For example:
1) How much return do we get from spending X amount on marketing?
2) How should we allocate our marketing budget to maximise our sales?
Because these questions are mainly causal, it makes sense to use commonly accepted methods for studying causality to measure the impact
of marketing and the ROMI. Randomised experiments and the potential
outcomes framework (Imbens and Rubin, 2015) are perhaps the most common ones of these methods and researchers regularly apply them in other
fields. Randomised experiments have also been applied successfully to
measure marketing effectiveness, and their cost has been brought down
by the Internet and digital measurement infrastructures (Lewis and Rao,
2015). Thanks to their effectiveness, they have also become a part of the
innovation process of many businesses, such as Amazon and Microsoft
(Kohavi et al., 2009) and incorporated into advertising tools of Google and
Facebook (Facebook, 2015; Google, 2018). However, they also have several
barriers that prevent their adoption. For example, to reveal the S-curve,
experiments must be done at various levels of advertising spending, which
can be costly. Moreover, the need and cost of having large control groups to
measure weak effects limit the opportunities in their use.

Because of the impracticality of the conventional methods for studying
causality, companies often resort to using more straightforward marketing
mix modelling (MMM), aka media mix modelling, techniques. MMM attempts to model the demand response by fitting a model, typically an OLS
regression with various drivers and control factors, in historical data (Chan
and Perry, 2017). The results commonly include ROAS estimates for advertising channels and a break-down of the effect of different drivers. The
technique is cheap, fast and straightforward to apply as it typically involves
no experimentation. Yet, the validity of the results is often questionable.
The models are often based on inaccurate or unverified assumptions about
the nature of marketing environment (Zhang and Vaver, 2017) and are
merely capable of producing correlational, not causal results (Chan and
Perry, 2017).

Data used to fit marketing mix models are typically historical weekly or monthly aggregated national
data, although geo-level data can be used. The data includes:
 response data, typically sales but can be other KPI
 media metrics by channel, such as impressions, clicks, GRPs, with the cost being the most
commonly used
 marketing metrics such as price, promotion, product distribution
 control factors such as seasonality, weather or competition.
The response data needs to be at the same level of granularity as the ads spend data. So, while an
advertiser may have precise SKU level data, advertising is usually done at a brand or
product level over an entire country. For the response data, such as sales, advertisers have in place a
robust data collection mechanism. However, media data is more challenging to collect, as ad
campaigns are often executed through several intermediaries, such as agencies or online platforms.
Since it is difficult to get competitor variables for pricing, promotion, and distribution through thirdparties, these variables are often omitted (Chan & Perry, 2017).


MMM typically uses four types of
data to fit their models:
• response data, which are typically volume or sales data,
• media metrics, which are commonly media spending data but sometimes other KPIs such as impressions and clicks,
• marketing metrics such as price, promotions, product distribution,
and
• control factors such as seasonality, weather and market competition.

If suitable data are available, modellers can fit models on various levels
of data aggregation, for example, ranging from the level of an individual
product to the total business unit level, as presented in Figure 2.5 by Cain
(2010).

The lower the level of the fitting, the more detailed conclusions
can be drawn from the results. However, data granularity often limits
the choice. As described by Chan and Perry (2017), companies typically
have granular sales data on SKU or store level but do their advertising
on a higher level over an entire country. As the data types in the model
should preferably be on the same aggregation level, the least granular
data type often sets the granularity of the whole model. Thus, models
are often fitted on the national level using weekly or monthly aggregated
data. Moreover, some of the data types may be difficult to obtain. For
example, companies often omit competitor data, such as marketing efforts
and prices, or ad exposure data, especially for offline media, because of
the difficulty of collecting reliable data. The omission can, in turn, lead to
inaccuracies in modelling. Overall, the lack of (reliable) data is one of the
main limitations of MMM.

 Limitations of marketing mix modelling
As described by Chan and Perry (2017), the results from a regression-based
marketing mix model cannot be claimed to be causal in general, but they
are likely to be more trustworthy when:
• enough data are available to estimate all the parameters in the model,
• useful variability exists in the advertising levels and control variables,
• the model inputs vary independently,
• the model accounts for all the important sales drivers, and
• the model captures the causal relationship between variables.

Despite the importance of these conditions, models often fail to meet them,
limiting not only the reliability of results and but also the scope of the
analysis. Overall, these and many other challenges limit the opportunities
in MMM:
The lack of data limits the reliability of the results and the model granularity. As mentioned in Section 2.3.1, companies typically may have
accurate data on sales but lack granular data on marketing. Low
granularity in one data type can limit the whole model to the same
level, forcing the modeller to aggregate other data types. The aggregation leads to a data set with a low number of data points. For
example, a three-year data set of weekly-aggregated data has only
156 data points. If a company has several advertising channels, each
of which is modelled with several parameters, the number of data
points per parameter in the model can quickly become quite low. The
result might be an unstable regression fit that gives poor estimates
(Chan and Perry, 2017). Many researchers have suggested that the
number of observations should be at least five times the number of
parameters (Leeflang et al., 2015). The lack of data can also lead to
the omission of variables. For example, companies often fail to gather
data about various control activities with a sales impact, such as competitor activity, leading to possible errors because of their omission.

Data reliability is also crucial for the reliability of results. If the modeller feeds inaccurate data to the model, it will only produce inaccurate results. One typical source of inaccuracies is the lack of
systematic data collection. For example, Karmann et al. (2015) note
that it is often a significant challenge for companies to measure their
marketing spending fully. Spending may, for example, become buried
in the budgets of different departments and local subsidiaries and
never become registered in the main marketing department.

A limited range of data creates extrapolation uncertainty when esti19
Measuring marketing effectiveness
mating sales outside the observed budget range (Chan and Perry,
2017). For example, if an advertiser wants to estimate the average
ROAS of an advertising channel, it needs to estimate the level of
sales at zero spending. If no data near zero spending is available,
extrapolation may produce inaccurate results if the S-curve suddenly
changes outside the available range. Thus, a model may produce accurate results for the marginal ROAS but fail to produce reasonable
estimates for the total ROAS.

The lack of model validation and evaluation limits model reliability.
As described by Zhang and Vaver (2017), drawing causal results
from MMM requires making assumptions about the nature of the
marketing environment. Although these assumptions are inevitably
inaccurate to some extent, they also remain unidentified or unverified
in many situations. In some cases, they may also even be unverifiable. The inaccuracies and omissions of assumptions, in turn, reduce
the reliability of the results. Consequently, Zhang and Vaver state
that both observational and experimental methods require careful
evaluation and validation. With observational methods, such as
marketing mix modelling, modellers should attempt to verify the
accuracy of result estimates against a source of truth, for example,
from a simulation experiment.

Correlated input parameters are a typical problem with MMM: advertisers often seek to maximise the impact of marketing efforts by
investing in them in a correlated way. For example, an advertising
channel could be observed at a high level only when a significant
discount is in place or only during a specific season. In a linear
regression model, this correlation can lead to coefficient estimates
with variance and thus, lead to a wrong attribution of sales to the
advertising channel (Chan and Perry, 2017).

Selection bias is a major hurdle for MMM. As described by Chan and
Perry (2017), it occurs when an input media variable correlates with
an unobservable demand parameter that drives sales. When that
parameter is left outside the regression, the model falsely attributes
sales to the media instead of the unobservable parameter. The bias
can be caused, for example, by:
1. Ad targeting – Especially in digital channels, selection bias occurs when ads are shown to people who are already interested in the
product, for example, when showing ads for a related search query.
If the underlying interest remains unaccounted for, it can lead to
false attribution.

2. Seasonality – Unknown or inaccurately modelled seasonality can
lead to selection bias as well. For example, a holiday can cause an
increase in sales that becomes falsely attributed to an advertising
channel. Similarly, competitors’ marketing efforts are not often
accounted for because no data of them are often available.

3. Funnel effects – Selection bias also occurs when the level of one
advertising channel affects the level of another one. For example, a
TV ad might drive more search queries leading to more paid search
ads.

Short-termism is a weakness of MMM as well. Conventional MMM
focuses on measuring short-term incremental sales that will consequently, only provide an estimate of the short-term ROAS. Cain
(2010) repeats the critique by Ambler and Roberts (2005) and Rust
et al. (2004) by stating that this focus disregards the potential brandbuilding and brand-eroding effects of marketing and often leads to a
bias towards promotion activity, where incremental sales are more
immediate than in, for example, media activity. He suggests that to
measure long-term effects, models must also focus on the base sales
component of the model. The base sales reflect the changes in underlying marketing assets, for example, by growing when new customers
convert into loyal customers that make repeated purchases. 

However, according to Cain, the standard OLS regression models are only
capable of imposing a fixed or deterministic baseline that prevents
the analysis of the long-term impact of marketing. Consequently, he
suggests the use of time series regression models to decompose the
sales into short-term (incremental) and long-term base (trend) sales.

Past performance may not be the best indicator for future performance.
Conventional MMM only provides an estimate of the past performance but does not specifically attempt to estimate what the performance will be in the future. Customer behaviour and market
conditions may change in the future and affect marketing performance and S-curves. Thus, the results from MMM should be used
with caution when making decisions.

ROMI-managed companies extensively use econometric or marketing mix models to aid the marketing mix decision-making process. The models help optimize ROMI beyond improving the measurement of returns; they allow marketing analysts to virtually estimate potential outcomes across a variety of circumstances performing “what-if scenarios” and to evaluate more quickly and efficiently a wide range of alternative options. MMM adds a critically important capability to ROMI management when building on a foundation of definitions and metrics developed through cross-functional teamwork.

Marketers have used MMM to move beyond cost management to optimize their mix and manage their top-line opportunities.

Minute Maid has turned its MMMs into a potent tool for increasing the payback on its advertising spending. These models are updated every six months for all major brands and the learning gained in the process is used for planning purposes.

MMMs allow marketers to estimate potential outcomes across a variety of circumstances—able to evaluate alternative hypotheses and select those most likely to payoff and to test them more rigorously because they do not have to test a thousand options. MMM tools can be productive as a means by which users enrich their judgmental processes by adding to their learning.

MMM is often criticized for its “rear-view mirror” or after the fact perspective of marketing mix impact. However, new simulation models can provide scenarios for managers to assess future potential results. 

To aid in evaluating new products, they have begun Monte Carlo simulations integrating the degrees of uncertainty and drivers of a project. The simulations enable the marketing team to assess the range of potential outcomes and to apply market models and to assess discounted cash flow. The analysis allows the understanding of likely outcomes to gain a degree of confidence of the amount of risk. Their risk-adjustment net-present-value model adjusts the hurdle rate over the life of the project to more accurately reflect the degree of risk that the organization is taking.“What-if” simulations permit marketing analysts to evaluate their databases and models, as well as testing out alter-native marketing options. Also, “What-if” or “Due-to” analyses can turn a postmortem on a disappointing promotion into a springboard to new, more effective programs for the future.
